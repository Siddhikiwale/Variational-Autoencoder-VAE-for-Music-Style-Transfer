{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi\n",
        "!pip install o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJEIGiFGam4b",
        "outputId": "c9b90425-882c-44b1-fa1e-0282a0faf6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.11/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (24.2)\n",
            "Requirement already satisfied: o in /usr/local/lib/python3.11/dist-packages (0.0.2b2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import soundfile as sf\n",
        "from scipy.signal import resample"
      ],
      "metadata": {
        "id": "H4PJWpgvakLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#      Load & Preprocess Audio  #\n"
      ],
      "metadata": {
        "id": "s1g7V72RlBDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(file_path, target_sr=22050):\n",
        "    audio, sr = librosa.load(file_path, sr=target_sr)\n",
        "    return audio, sr"
      ],
      "metadata": {
        "id": "pO_NrIlskaXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#         Encoder Model         #"
      ],
      "metadata": {
        "id": "49JnYk9llXg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_encoder(latent_dim, input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling1D(2, padding='same')(x)\n",
        "    x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling1D(2, padding='same')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
        "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "    return encoder"
      ],
      "metadata": {
        "id": "ZCJ7r5julUid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#         Decoder Model         #"
      ],
      "metadata": {
        "id": "6YwmdXEZlsOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_decoder(latent_dim, output_shape):\n",
        "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(output_shape[0] * output_shape[1], activation='relu')(latent_inputs)\n",
        "    x = layers.Reshape(output_shape)(x)\n",
        "\n",
        "    x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling1D(2)(x)\n",
        "    x = layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling1D(2)(x)\n",
        "    outputs = layers.Conv1D(output_shape[1], 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "    return decoder"
      ],
      "metadata": {
        "id": "YGFeYWmQkl1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#       VAE Class        #"
      ],
      "metadata": {
        "id": "2oOdSCF8lo7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "        self.add_loss(kl_loss)\n",
        "        return reconstructed\n"
      ],
      "metadata": {
        "id": "SBpjhf6gkotU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#       Mix & Manipulate Audio  #"
      ],
      "metadata": {
        "id": "7d2ylX0hlmM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mix_audio(audio1, audio2, alpha=0.5):\n",
        "    min_length = min(len(audio1), len(audio2))\n",
        "    mixed = alpha * audio1[:min_length] + (1 - alpha) * audio2[:min_length]\n",
        "    return mixed\n",
        "\n",
        "def change_speed(audio, factor):\n",
        "    return resample(audio, int(len(audio) * factor))"
      ],
      "metadata": {
        "id": "N78g4WF_kry2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#       Execution & Training    #"
      ],
      "metadata": {
        "id": "w8HGNbewlj6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 16\n",
        "input_shape = (22050, 1)\n",
        "encoder = build_encoder(latent_dim, input_shape)\n",
        "decoder = build_decoder(latent_dim, input_shape)\n",
        "vae = VAE(encoder, decoder)\n",
        "\n",
        "# Load two different MP3 files\n",
        "audio1, sr1 = load_audio('/content/Piano sa re ja ma pa.mp3')\n",
        "audio2, sr2 = load_audio('/content/Sa re ja ma pa.mp3')\n",
        "\n",
        "# Mix & Manipulate\n",
        "audio_mixed = mix_audio(audio1, audio2, alpha=0.5)\n",
        "audio_slow = change_speed(audio_mixed, 1.2)\n",
        "audio_fast = change_speed(audio_mixed, 0.8)\n",
        "\n",
        "# Save processed audio\n",
        "sf.write('mixed_audio.wav', audio_mixed, sr1)\n",
        "sf.write('slow_audio.wav', audio_slow, sr1)\n",
        "sf.write('fast_audio.wav', audio_fast, sr1)\n",
        "\n",
        "# Train the VAE\n",
        "# (This is a placeholder; you need to define your training process)\n",
        "# train_vae([audio1, audio2], vae, epochs=10)\n",
        "\n",
        "# Generate music\n",
        "random_latent_vector = np.random.normal(size=(1, latent_dim))\n",
        "generated_audio = decoder.predict(random_latent_vector)\n",
        "sf.write('generated_music.wav', generated_audio[0], sr1)\n",
        "\n",
        "print(\"✅ Music Style Transfer Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn0MUuEKku_d",
        "outputId": "6243f4f8-6faf-4eab-99be-9244c1378147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step\n",
            "✅ Music Style Transfer Complete!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}